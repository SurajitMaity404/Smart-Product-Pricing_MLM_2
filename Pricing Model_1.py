# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zemaGlmqLpTPtJUziwT5XT3sB0MXHha4
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
train_df = pd.read_csv('/content/train.csv')
test_df = pd.read_csv('/content/test.csv')
print("Train head:\n", train_df.head())
print("Test head:\n", test_df.head())
print("Train shape:", train_df.shape)
print("Test shape:", test_df.shape)
print("Train missing:\n", train_df.isnull().sum())
print("Test missing:\n", test_df.isnull().sum())
print("Train price stats:\n", train_df['price'].describe())
print("Text length stats:\n", train_df['catalog_content'].str.len().describe())

!pip install torch torchvision transformers pandas numpy pillow requests scikit-learn tqdm

import os
import requests
from PIL import Image
from io import BytesIO
from tqdm import tqdm

def download_image(url, save_path):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        img = Image.open(BytesIO(response.content))
        img.save(save_path)
        return True
    except Exception as e:
        print(f"Failed to download {url}: {e}")
        return False

train_img_dir = '/content/images/train/'
test_img_dir = '/content/images/test/'

sample_size = 1000  # Set to 75000 for full dataset
train_subset = train_df.head(sample_size)
for idx, row in tqdm(train_subset.iterrows(), total=len(train_subset), desc="Downloading train images"):
    save_path = f"{train_img_dir}{row['sample_id']}.jpg"
    if not os.path.exists(save_path):
        download_image(row['image_link'], save_path)

from google.colab import files
import os
os.makedirs('/content/images/train/', exist_ok=True)
os.makedirs('/content/images/test/', exist_ok=True)
print("Upload train images:")
uploaded_train = files.upload()  # Upload train images
for name, data in uploaded_train.items():
    with open(f'/content/images/train/{name}', 'wb') as f:
        f.write(data)
print("Upload test images:")
uploaded_test = files.upload()  # Upload test images
for name, data in uploaded_test.items():
    with open(f'/content/images/test/{name}', 'wb') as f:
        f.write(data)

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, BertModel
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import os
import warnings
warnings.filterwarnings('ignore')

# Device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

# Load Data
train_df = pd.read_csv('/content/train.csv')
test_df = pd.read_csv('/content/test.csv')

# Preview
print("Train head:\n", train_df.head())
print("Test head:\n", test_df.head())
print("Train shape:", train_df.shape)
print("Test shape:", test_df.shape)
print("Train missing:\n", train_df.isnull().sum())
print("Test missing:\n", test_df.isnull().sum())
print("Train price stats:\n", train_df['price'].describe())
print("Text length stats:\n", train_df['catalog_content'].str.len().describe())

# Text Features (BERT)
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)
bert_model.eval()
def get_bert_embedding(text, max_len=128):
    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=max_len).to(device)
    with torch.no_grad():
        outputs = bert_model(**inputs)
    return outputs.last_hidden_state[:, 0, :].cpu().numpy()  # 768-dim

# Image Features (ResNet-50)
resnet = models.resnet50(pretrained=True).to(device)
resnet.eval()
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

def get_resnet_features(sample_id, img_dir):
    img_path = f"{img_dir}{sample_id}.jpg"
    try:
        img = Image.open(img_path).convert('RGB')
        img_t = transform(img).unsqueeze(0).to(device)
        with torch.no_grad():
            features = resnet(img_t).cpu().numpy()  # 2048-dim
        return features.flatten()
    except:
        return np.zeros(2048)  # Dummy for failed loads

# Extract Features (subset for demo)
sample_size = 1000  # Set to 75000 for full dataset
train_subset = train_df.head(sample_size)
text_embeds = np.vstack([get_bert_embedding(text) for text in tqdm(train_subset['catalog_content'], desc='Train Text')])
image_embeds = np.vstack([get_resnet_features(row['sample_id'], '/content/images/train/') for _, row in tqdm(train_subset.iterrows(), desc='Train Image')])
X = np.hstack([text_embeds, image_embeds])
y = train_subset['price'].values

# Normalize
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()

# Dataset
class ProductDataset(Dataset):
    def __init__(self, X, y=None):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1) if y is not None else None

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        if self.y is not None:
            return self.X[idx], self.y[idx]
        return self.X[idx]

# Split
X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)
train_ds = ProductDataset(X_train, y_train)
val_ds = ProductDataset(X_val, y_val)
train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=32)

# Model
class PricePredictor(nn.Module):
    def __init__(self, input_size=2816):
        super().__init__()
        self.fc1 = nn.Linear(input_size, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 128)
        self.fc4 = nn.Linear(128, 1)
        self.dropout = nn.Dropout(0.3)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = torch.relu(self.fc2(x))
        x = self.dropout(x)
        x = torch.relu(self.fc3(x))
        return self.fc4(x)

model = PricePredictor().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)

# Train
epochs = 20  # Increase to 50 for full dataset
best_val_loss = float('inf')
for epoch in range(epochs):
    model.train()
    train_loss = 0
    for batch_X, batch_y in train_loader:
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        optimizer.zero_grad()
        output = model(batch_X)
        loss = criterion(output, batch_y)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    model.eval()
    val_loss = 0
    preds, trues = [], []
    with torch.no_grad():
        for batch_X, batch_y in val_loader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            output = model(batch_X)
            val_loss += criterion(output, batch_y).item()
            preds.extend(output.cpu().numpy())
            trues.extend(batch_y.cpu().numpy())

    train_loss /= len(train_loader)
    val_loss /= len(val_loader)
    preds = scaler_y.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()
    trues = scaler_y.inverse_transform(np.array(trues).reshape(-1, 1)).flatten()
    mae = mean_absolute_error(trues, preds)
    r2 = r2_score(trues, preds)

    scheduler.step(val_loss)
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), '/content/best_model.pth')

    print(f'Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | MAE: ${mae:.2f} | RÂ²: {r2:.4f}')

# Test Predictions
test_text_embeds = np.vstack([get_bert_embedding(text) for text in tqdm(test_df['catalog_content'], desc='Test Text')])
test_image_embeds = np.vstack([get_resnet_features(row['sample_id'], '/content/images/test/') for _, row in tqdm(test_df.iterrows(), desc='Test Image')])
X_test = np.hstack([test_text_embeds, test_image_embeds])
X_test_scaled = scaler_X.transform(X_test)

test_ds = ProductDataset(X_test_scaled)
test_loader = DataLoader(test_ds, batch_size=32)

preds_scaled = []
model.load_state_dict(torch.load('/content/best_model.pth'))
model.eval()
with torch.no_grad():
    for batch_X in test_loader:
        batch_X = batch_X.to(device)
        output = model(batch_X)
        preds_scaled.extend(output.cpu().numpy())

preds = scaler_y.inverse_transform(np.array(preds_scaled).reshape(-1, 1)).flatten()
output_df = pd.DataFrame({'sample_id': test_df['sample_id'], 'price': preds})
output_df.to_csv('/content/predictions.csv', index=False)

print("\nPredictions saved to /content/predictions.csv")
print(output_df.head())
print(f"Prediction stats: Mean ${preds.mean():.2f}, Min ${preds.min():.2f}, Max ${preds.max():.2f}")

# Download predictions.csv to laptop
from google.colab import files
files.download('/content/predictions.csv')